{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import torch\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import random\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "from model.split import Stemmer\n",
    "from model.net import BidiEncoder, AttnDecoder\n",
    "from model.utils import SourceProcessor, TargetProcessor\n",
    "from model.data import NMTCorpus, batchify\n",
    "from utils import Config, CheckpointManager, SummaryManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load configs\n",
    "model_config = Config(\"conf/model/luongattn.json\")\n",
    "dataset_config = Config(\"conf/dataset/sample.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get processors\n",
    "def get_processor(dataset_config):\n",
    "    with open(dataset_config.source_vocab, mode=\"rb\") as io:\n",
    "        src_vocab = pickle.load(io)\n",
    "    src_stemmer = Stemmer(language=\"ko\")\n",
    "    src_processor = SourceProcessor(src_vocab, src_stemmer.extract_stem)\n",
    "\n",
    "    with open(dataset_config.target_vocab, mode=\"rb\") as io:\n",
    "        tgt_vocab = pickle.load(io)\n",
    "    tgt_stemmer = Stemmer(language=\"en\")\n",
    "    tgt_processor = TargetProcessor(tgt_vocab, tgt_stemmer.extract_stem)\n",
    "    return src_processor, tgt_processor\n",
    "\n",
    "src_processor, tgt_processor = get_processor(dataset_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttnDecoder(\n",
       "  (_emb): Embedding(\n",
       "    (_ops): Embedding(5085, 300, padding_idx=1)\n",
       "  )\n",
       "  (_ops): LSTM(300, 512, num_layers=2, batch_first=True, dropout=0.3)\n",
       "  (_attn): GlobalAttn()\n",
       "  (_concat): Linear(in_features=1024, out_features=300, bias=False)\n",
       "  (_dropout): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restore model\n",
    "exp_dir = Path('experiments') / model_config.type\n",
    "exp_dir = next(exp_dir.iterdir())\n",
    "checkpoint_manager = CheckpointManager(exp_dir)\n",
    "\n",
    "encoder = BidiEncoder(\n",
    "    src_processor.vocab, model_config.encoder_hidden_dim, model_config.drop_ratio\n",
    ")\n",
    "decoder = AttnDecoder(\n",
    "    tgt_processor.vocab,\n",
    "    model_config.method,\n",
    "    model_config.encoder_hidden_dim * 2,\n",
    "    model_config.decoder_hidden_dim,\n",
    "    model_config.drop_ratio\n",
    ")\n",
    "\n",
    "checkpoint = checkpoint_manager.load_checkpoint(\"best.tar\")\n",
    "encoder.load_state_dict(checkpoint[\"encoder_state_dict\"])\n",
    "decoder.load_state_dict(checkpoint[\"decoder_state_dict\"])\n",
    "\n",
    "encoder.eval()\n",
    "decoder.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepair example pair\n",
    "tr = pd.read_csv(dataset_config.train, sep='\\t')\n",
    "example_pair = tr.iloc[random.randint(0, len(tr))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['나', '의', '장래', '희망', '은', '자동차', '디자이너', '입니다', '.']\n",
      "['my', 'dream', 'is', 'to', 'be', 'a', 'car', 'design', '.', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "print(src_processor.vocab.to_tokens(src_processor.process(example_pair.ko)))\n",
    "print(tgt_processor.vocab.to_tokens(tgt_processor.process(example_pair.en)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(source_sentence, max_len=50, src_processor=src_processor, tgt_processor=tgt_processor):\n",
    "    with torch.no_grad():\n",
    "        src = torch.tensor(src_processor.process(source_sentence)).unsqueeze(0)\n",
    "        \n",
    "        enc_outputs, src_length, enc_hc = encoder(src)\n",
    "        dec_input = torch.ones((1, 1)).long()\n",
    "        dec_input *= tgt_processor.vocab.to_indices(tgt_processor.vocab.bos_token)\n",
    "        dec_hc = None\n",
    "\n",
    "        translation = [tgt_processor.vocab.bos_token]\n",
    "        \n",
    "        for time_step in range(max_len):\n",
    "            dec_output, dec_hc = decoder(dec_input, dec_hc, enc_outputs, src_length)\n",
    "            dec_input = dec_output.topk(1).indices\n",
    "            token = tgt_processor.vocab.to_tokens(dec_input.item())\n",
    "            translation.append(token)\n",
    "            \n",
    "            if token == tgt_processor.vocab.eos_token:\n",
    "                break\n",
    "    \n",
    "    return translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<bos>', 'my', 'dream', 'is', 'a', 'car', 'design', '.', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "translation = translate(example_pair.ko)\n",
    "print(translation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
